# -*- coding: utf-8 -*-
"""ANN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g5YApzfvGDV9LgtaW72s9HEXr3HA6vqb
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
import matplotlib.pyplot as plt

print("TensorFlow ë²„ì „:", tf.__version__)

# 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
print("\nğŸ“¦ ë°ì´í„° ë¡œë”© ì¤‘...")
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

# ë°ì´í„° ì •ê·œí™” (0-255 -> 0-1)
x_train = x_train.astype("float32") / 255.0
x_test = x_test.astype("float32") / 255.0

# 28x28 ì´ë¯¸ì§€ë¥¼ 784ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜
x_train = x_train.reshape(-1, 28 * 28)
x_test = x_test.reshape(-1, 28 * 28)

print(f"í›ˆë ¨ ë°ì´í„° í˜•íƒœ: {x_train.shape}")
print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° í˜•íƒœ: {x_test.shape}")

# 2. ANN ëª¨ë¸ êµ¬ì¶•
print("\nğŸ—ï¸  ëª¨ë¸ êµ¬ì¶• ì¤‘...")
model = keras.Sequential([
    layers.Input(shape=(784,)),
    layers.Dense(128, activation='relu', name='hidden_layer_1'),
    layers.Dropout(0.2),
    layers.Dense(64, activation='relu', name='hidden_layer_2'),
    layers.Dropout(0.2),
    layers.Dense(10, activation='softmax', name='output_layer')
])

# ëª¨ë¸ ì»´íŒŒì¼
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# ëª¨ë¸ êµ¬ì¡° ì¶œë ¥
model.summary()

# 3. ëª¨ë¸ í•™ìŠµ
print("\nğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
history = model.fit(
    x_train, y_train,
    batch_size=128,
    epochs=10,
    validation_split=0.1,
    verbose=1
)

# 4. ëª¨ë¸ í‰ê°€
print("\nğŸ“Š ëª¨ë¸ í‰ê°€ ì¤‘...")
test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)
print(f"\ní…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_accuracy*100:.2f}%")
print(f"í…ŒìŠ¤íŠ¸ ì†ì‹¤: {test_loss:.4f}")

# 5. í•™ìŠµ ê³¼ì • ì‹œê°í™”
plt.figure(figsize=(12, 4))

# ì •í™•ë„ ê·¸ë˜í”„
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='í›ˆë ¨ ì •í™•ë„')
plt.plot(history.history['val_accuracy'], label='ê²€ì¦ ì •í™•ë„')
plt.title('ëª¨ë¸ ì •í™•ë„')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)

# ì†ì‹¤ ê·¸ë˜í”„
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='í›ˆë ¨ ì†ì‹¤')
plt.plot(history.history['val_loss'], label='ê²€ì¦ ì†ì‹¤')
plt.title('ëª¨ë¸ ì†ì‹¤')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

